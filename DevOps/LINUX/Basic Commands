

# replace mysql with MYSQL and copy to a new file
sed s/mysql/MYSQL/g snort.conf.copy > snort.conf.copy2

# searching for '$Work' string and showing 5 lines before/above, not showing line containing '$Work', showing line numbers as well
nl /etc/rsyslog.conf |grep '$Work' -B 5 | grep -v '$Work'

# searching for sources.list list and removing it, starting with root
find /var/lib/apt/sources.list -type f -exec rm {} \;

#
find /var/lib/apt/sources.list -type f -exec rm {} \;

CWD="$(pwd)"

# finding files with json and conf extensions, using logical -or, line numbers included
 sudo find /etc -name *.json -o -name *.conf | nl
 sudo find /etc -name java* -type f  -o -type d -name *java* |nl > nginx.file3

# showing only words from a first column (-f1) and delimiter is comma (-d:). results are numbered

# CUT command
 sudo cat /etc/passwd |cut -d: -f1 |nl

# GREP command 
# (^) - start of each line
# ([^:]*) - no colons
 sudo cat /etc/passwd |grep -o '^[^:]*' |nl

# AWK command
 sudo cat /etc/passwd |awk -F ':' '{print $1}'|nl

# excluding errors ( 2>/dev/null )
    find /etc 2>/dev/null -type f -size +500k

# showing size of a file, using cut
path=/path/to/file
sudo ls -lash $path | cut -d' ' -f1

# deleting files larger than 1K
 find . -type f -size +1k -exec rm -f {} \;

# SED and AWK

# (-e) is necessary if multiple instructions are supplied on command line 
sed 's/ MA/ , Massachusetts/; s/ PA/, Pennsylvania' email.list
sed -e 's/ MA/ , Massachusetts/' -e 's/ PA/ , Pennsylvania/' email.list

# replacing " ," with ", "
# converting (,Massachusetts) to (, Massachusetts)

sed "s/ ,/, /" email.list2
sed -e "s/ ,/, /" email.list2

# removing space from first column
sed -e "s/^ *//" email.list

# using scripts
sed -f sedscr file
# 'file' that is changed
# 'sedscr' file containing commands for the script
cat sedscr
s/ MA/, Massachusetts/
s/ PA/, Pennsylvania/
s/ CA/, California/
s/ VA/, Virginia/
s/ OK/, Oklahoma/

# example
sed -f sedscr email.list
# capturing changes in a newfile
sed -f sedscr email.list > email.list.new

# prints first field from the output
 awk '{print $1}' email.list

# printing multiple columns
awk '{print $3" "$4" "$5}' email.list

# '-F' defines the delimiters, in this case ' ' and '%'. printing first two columns
awk -F'[ %]'  '{print $1" "$2}' email.list.3

# selecting based on condition 'VA'
awk '/VA/' email.list

# TOP, getting snapshot of one interaction '-b' batch mode  
top -b -n 1 > top.list

# filtering 10000 records from PID column header, awk filters values where  (CPU) '$9' is more than 0
cat top.list | grep -E PID -A 10000 | awk '{if($9>0)print $1" "$2" "$9" "$10" "$12}'|more

################### raw top command output
top - 13:08:39 up  4:05,  2 users,  load average: 0.02, 0.02, 0.00
Tasks: 115 total,   1 running, 113 sleeping,   1 stopped,   0 zombie
%Cpu(s):  0.0 us,  4.0 sy,  0.0 ni, 96.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
MiB Mem :   5968.1 total,   5315.9 free,    458.0 used,    419.4 buff/cache
MiB Swap:    975.0 total,    975.0 free,      0.0 used.   5510.2 avail Mem

    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
      1 root      20   0   21068  12492   9292 S   0.0   0.2   0:01.98 systemd
      2 root      20   0       0      0      0 S   0.0   0.0   0:00.04 kthreadd

################### raw top command output

################### AFTER running 'awk'
PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
   1809 kk        20   0    8756   4992   2944 R   9.1   0.1   0:00.02 top
      1 root      20   0   21068  12492   9292 S   0.0   0.2   0:01.96 systemd
      2 root      20   0       0      0      0 S   0.0   0.0   0:00.03 kthreadd
      3 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 rcu_gp
      4 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 rcu_par+

################### AFTER running 'awk'



cat top.list | grep -E PID -A 10000 | awk '{if($9>0)print $1" "$2" "$9" "$10" "$12}'|more

# selecting processes that have uptime more than 0, printing all colums '$0'
ps -ax | grep -E PID -A 100 | awk '{if($4 != "0:00")print $0}'


# nameState
s/ CA/, California/
s/ MA/, Massachusetts/
s/ OK/, Oklahoma/
s/ PA/, Pennsylvania/
s/ VA/, Virginia/

# email.list.new
John Daggett, 341 King Road, Plymouth, Massachusetts
Alice Ford, 22 East Broadway, Richmond, Virginia
Orville Thomas, 11345 Oak Bridge Road, Tulsa, Oklahoma
Terry Kalkas, 402 Lans Road, Beaver Falls, Pennsylvania
Eric Adams, 20 Post Road, Sudbury, Massachusetts
Hubert Sims, 328A Brook Road, Roanoke, Virginia
Amy Wilde, 334 Bayshore Pkwy, Mountain View, California
Sal Carpenter, 73 6th Street, Boston, Massachusetts

# printing only 4th column
sed -f nameState email.list.new | awk -F, '{print $4}'

# counting occurences of each state, sorting states alphabetically 
sed -f nameState email.list.new | awk -F, '{print $4}' |sort | uniq -c


# sorting names of people by state and printing state name and names after

### shell script 'byState'
#! /bin/sh
awk -F, '{ print $4 ", " $0}' $* |
sort |
awk -F, '$1 == LastState {print "\t" $2} $1 != LastState {LastState = $1 print $1 print "\t" $2}'

cat gcutError_recon-all.log | grep Subject[0-90-9] | sort | uniq -c | tail

# showing pattern along with line numbers
cat gcutError_recon-all.log | grep "hostname" -n

# number of occurences
cat gcutError_recon-all.log | grep "hostname" | wc -l

# OR, 'mri_segstats done' OR 'user '
cat gcutError_recon-all.log | grep  'mri_segstats done\|user '

# the same but using extended regexp '-E'
cat gcutError_recon-all.log | grep -E 'mri_segstats done|user '

# EGREP does not need -E
cat gcutError_recon-all.log | egrep  'mri_segstats done|user '

# searching for NOT '/home' but containing 'home'
cat gcutError_recon-all.log | grep  -v '/home' | grep ' home'

# using wildcard '.*'
cat gcutError_recon-all.log | grep   'home.*language' 

# 
cat gcutError_recon-all.log | grep -E 'before.*smoothing|after.*smoothing'

# searching for '. ' pattern => dot and space
cat gcutError_recon-all.log | grep  '\. '

# matches 12.04 or 12.044. first dot is escaped and second acts as a wildcard
cat gcutError_recon-all.log | grep  '12\.[0-1].4'

# matches end-of-line '$' ending with ';'
cat gcutError_recon-all.log | grep '\;$'

# example
 0.000   0.000   1.000  -128.000;
 0.000  -1.000   0.000   128.000;
 0.000   0.000   0.000   1.000;

cat gcutError_recon-all.log | grep '*[Ww].*'
*************************WATERSHED**************************

# showing lines with 'global' or with '*'
cat gcutError_recon-all.log | grep  '*[Ww].*\|global'
*************************WATERSHED**************************
      global maximum in x=110, y=91, z=90, Imax=255



# Transform matrix and 4 lines below/after, exclude line with 'Transform' or '--'', squeeze all white spaces 'tr'
cat gcutError_recon-all.log | grep  'Transform matrix' -A 4 | grep -v 'Transform\|'--'' | tr -s ' '

# with AWK, there is no need to do white space squeeze (tr -s)
# it finds columsn automatically whether values are negative or positive
 awk '{print $1,$2}' list.old
1.26461 0.05558
-0.06622 1.37430
-0.11270 -0.18109
0.00000 0.00000
1.26461 0.05558

# similar results with GREP and CUT but it does not show negative values
cat gcutError_recon-all.log | grep  'Transform matrix' -A 4 | grep -v 'Transform\|'--'' > list.old

 
# sumowanie wartosci z pierwszej kolumny
awk '{sum+=$1}END{printf "%.2f", sum}' list.old  

# DATES
# catches formats such as MM-DD-YY and MM/DD/YY
cat date | grep '[0-1][0-9][-/][0-3][0-9][-/][0-9][0-9]$'
# first two characters are not digits '^' - INVERTED
cat date | grep '[^0-1][^0-9][-/][0-3][0-9][-/][0-9][0-9]$'

# excluding any vowels so only consonants (LPW etc..) will be shown
[Ë†aeiou]

# squeeze the white spaces, filter one or no space at the beginning of the line
cat gcutError_recon-all.log | tr -s ' ' |grep  '^ \/\|^\/'  |wc -l

# any character
cat gcutError_recon-all.log | tr -s ' ' |grep  '^ \/\|^\/'  |wc -l

# lines containing multiple whitespaces
grep '\([^ ]* \+\)\{3,\}' 

# better solution to catch 2 or more consecutive spaces
grep '[[:space:]]\{2,\}' test1

